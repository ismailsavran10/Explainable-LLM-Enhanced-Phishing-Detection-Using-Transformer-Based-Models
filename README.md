# Explainable-LLM-Enhanced-Phishing-Detection-Using-Transformer-Based-Models
This project presents an explainable and context-aware phishing detection framework for email security, combining transformer-based language models with large language model (LLM) reasoning. The system performs accurate phishing classification while generating human-readable explanations to support security analysis and decision-making.
ğŸ›¡ï¸ Explainable LLM-Enhanced Phishing Detection
Using Transformer-Based Language Models

An explainable, context-aware framework for email phishing detection combining Transformers and LLM reasoning

<br/>










</div>
âœ¨ Overview

This project introduces an explainable and context-aware phishing detection framework for email security, built upon transformer-based deep learning models and enhanced with Large Language Model (LLM) reasoning.

Unlike traditional phishing detectors that rely on static rules or shallow features, the proposed system learns semantic intent, contextual manipulation, and social engineering patterns directly from email content.
Beyond classification, it generates human-readable explanations, transforming black-box predictions into transparent security insights.

ğŸ”¥ Why This Matters

Modern phishing attacks are no longer simple spam messages.
They are carefully crafted, linguistically persuasive, and often multilingual.

Traditional approaches struggle because they:

Depend on fixed keyword lists

Fail to model long-range context

Lack interpretability for security analysts

This project directly addresses these limitations by combining:

Contextual language understanding + LLM-based reasoning + explainable outputs

ğŸ§  Core Contributions

âœ… High-accuracy phishing detection using transformer models

âœ… Binary and multi-class phishing classification

âœ… Explainable AI pipeline powered by LLMs

âœ… Hybrid analysis combining textual context and technical security indicators

âœ… Web-based deployment for real-time email analysis

ğŸ—ï¸ System Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Email Subject + Bodyâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Preprocessing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transformer Encoder          â”‚
â”‚ (XLM-RoBERTa)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Binary / Multi-Class Output  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Technical Signal Extraction  â”‚
â”‚ (URL structure, TLDs, etc.)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Reasoning Module         â”‚
â”‚ (Mistral)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Explainable Security Report  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§ª Models & Design Rationale
ğŸ”¹ Transformer Encoder â€” XLM-RoBERTa

XLM-RoBERTa was selected after extensive benchmarking against:

BERT

BERT-TURK

RoBERTa

ELECTRA

DistilBERT

mDeBERTa

ğŸ“Š Result:
99.21% accuracy in binary phishing detection, with superior performance on:

Multilingual content

Contextual deception

Low false-negative rates (critical for security systems)

ğŸ”¹ Large Language Model â€” Mistral-7B

The LLM serves as an explanation engine, not a classifier.

It transforms:

Model predictions

URL-based technical indicators

Linguistic cues

into clear, natural language explanations that justify why an email is considered phishing or safe.

ğŸ” Explainable AI (XAI) Strategy

Instead of opaque confidence scores, the system explains decisions using:

Suspicious URL patterns

Abnormal top-level domains (TLDs)

Social engineering keywords

Contextual inconsistencies

These signals are synthesized by the LLM into analyst-friendly explanations, making the system suitable for both end-users and cybersecurity professionals.

ğŸ“Š Experimental Results
Metric	Value
Binary Accuracy	99.21%
Phishing Recall	High
Precisionâ€“Recall Balance	Stable
Multi-Class Separation	Meaningful

The results confirm that contextual transformer models, when paired with explainable reasoning, are highly effective against sophisticated phishing attacks.
