# Explainable-LLM-Enhanced-Phishing-Detection-Using-Transformer-Based-Models
This project presents an explainable and context-aware phishing detection framework for email security, combining transformer-based language models with large language model (LLM) reasoning. The system performs accurate phishing classification while generating human-readable explanations to support security analysis and decision-making.
<div align="center">

# ğŸ›¡ï¸ Explainable LLM-Enhanced Phishing Detection  
## Using Transformer-Based Language Models

**An explainable and context-aware framework for email phishing detection  
combining Transformers and Large Language Model (LLM) reasoning**

<br/>

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Transformer](https://img.shields.io/badge/Model-Transformer-success)
![LLM](https://img.shields.io/badge/LLM-Mistral-orange)
![XAI](https://img.shields.io/badge/Explainable%20AI-XAI-critical)
![Status](https://img.shields.io/badge/Status-Research%20Ready-brightgreen)

</div>

---

## ğŸ“Œ Overview

This project presents an **explainable and context-aware phishing detection framework**
for email security, combining **transformer-based language models** with
**Large Language Model (LLM) reasoning**.

Unlike traditional phishing detection systems that rely on static rules or
handcrafted features, the proposed framework learns **semantic intent,
contextual manipulation, and social engineering patterns** directly from
email content.

Beyond classification, the system generates **human-readable explanations**,
transforming black-box predictions into **transparent security insights**
to support security analysts and decision-makers.

---

## ğŸ”¥ Why This Matters

Modern phishing attacks are no longer simple spam messages.
They are carefully crafted, linguistically persuasive, and often multilingual.

Traditional approaches struggle because they:

- âŒ Depend on fixed keyword lists  
- âŒ Fail to model long-range contextual dependencies  
- âŒ Lack interpretability for security analysts  

This project directly addresses these limitations by combining:

> **Contextual language understanding + LLM-based reasoning + explainable outputs**

---

## ğŸ§  Core Contributions

- âœ… High-accuracy phishing detection using transformer models  
- âœ… Binary and multi-class phishing classification  
- âœ… Explainable AI (XAI) pipeline powered by LLMs  
- âœ… Hybrid analysis combining textual context and technical security indicators  
- âœ… Web-based deployment for real-time email analysis  

---

## ğŸ—ï¸ System Architecture

Email Subject + Body
â†“
Text Preprocessing
â†“
Transformer Encoder (XLM-RoBERTa)
â†“
Binary / Multi-Class Classification
â†“
Technical Signal Extraction (URL, TLDs, etc.)
â†“
LLM Reasoning Module (Mistral)
â†“
Explainable Security Report

---

## ğŸ§ª Models & Design Rationale

### ğŸ”¹ Transformer Encoder â€” XLM-RoBERTa

XLM-RoBERTa was selected after extensive benchmarking against:

- BERT  
- BERT-TURK  
- RoBERTa  
- ELECTRA  
- DistilBERT  
- mDeBERTa  

**Result:**
- ğŸ¯ **99.21% accuracy** in binary phishing detection  
- ğŸŒ Superior performance on multilingual content  
- ğŸ›¡ï¸ Low false-negative rate (critical for security systems)  

---

### ğŸ”¹ Large Language Model â€” Mistral-7B

The LLM is used strictly as an **explanation engine**, not as a classifier.

It transforms:
- Model predictions  
- URL-based technical indicators  
- Linguistic and contextual cues  

into **clear, natural language explanations** describing *why* an email is
classified as phishing or legitimate.

---

## ğŸ” Explainable AI (XAI) Strategy

Instead of opaque confidence scores, the system explains decisions using:

- Suspicious URL structures  
- Abnormal top-level domains (TLDs)  
- Social engineering keywords  
- Contextual inconsistencies in email content  

These signals are synthesized by the LLM into
**analyst-friendly and user-readable explanations**.

---

## ğŸ“Š Experimental Results

| Metric | Value |
|------|------|
| Binary Classification Accuracy | **99.21%** |
| Phishing Recall | High |
| Precisionâ€“Recall Balance | Stable |
| Multi-Class Separation | Meaningful |

---
